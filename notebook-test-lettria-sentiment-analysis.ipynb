{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18fd6dd-09b3-4473-b760-9ed8b6fbbdb5",
   "metadata": {},
   "source": [
    "# TUTORIAL: Test Lettria model for sentiment analysis with AI notebooks\n",
    "\n",
    "The aim is to analyze sentiment of e-commerce site reviews thanks to Lettria model.\n",
    "\n",
    "- **What is a Lettria model?**\n",
    "\n",
    "Lettria is a start-up specialized in NLP (Natural Language Processing). The platform enables all organizations, from start-ups to large corporations, to perform textual analysis on their data to take the best strategic decisions.\n",
    "\n",
    "Lettria provides text understanding models that allow users to easily identify and extract key information from their text. This method relies on artificial intelligence and NLP techniques to extract **sentiments**, emotions and entities from a text.\n",
    "\n",
    "### Code:\n",
    "- Install dependencies\n",
    "- Import Python librairies\n",
    "- Load test dataset from Hugging Face hub and create a dataframe\n",
    "- Use Lettria app for sentiment analysis\n",
    "\n",
    "## Step 1 - Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37415b32-607d-4bf9-968e-69da40945075",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4245cfc-6cb5-479a-b8ab-3781eac7a685",
   "metadata": {},
   "source": [
    "## Step 2 - Import Python librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b6dc95-b754-4d87-a9ee-3ffdd52c0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from datasets import load_dataset\n",
    "\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33956b53-140f-4e54-8aa3-dc767da094c4",
   "metadata": {},
   "source": [
    "## Step 2 - Load test dataset from Hugging Face hub and create a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362f3da-b74d-4575-aa3f-ddd85d87e99f",
   "metadata": {},
   "source": [
    "- **Load test dataset and process output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9137ff6c-03ee-4bf9-b0a8-4bce61df5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset function (https://huggingface.co/datasets/amazon_reviews_multi)\n",
    "def womens_clothing_ecommerce_reviews():\n",
    "\n",
    "    # download test set from Hugging Face and display information\n",
    "    dataset = load_dataset(\"saattrupdan/womens-clothing-ecommerce-reviews\", \"test\")\n",
    "\n",
    "    # extract needed information and add it into a list for Dataset\n",
    "    dataset_test = []\n",
    "    for i in range(len(dataset['test'])):\n",
    "        info = {}\n",
    "        # extract sentence (str)\n",
    "        info['review_text'] = dataset['test'][i]['review_text']\n",
    "        # extract sentiment (int 1, 2, 3, 4, 5) -> (int 0, 1, 2, 3, 4)\n",
    "        polarity = dataset['test'][i]['rating']\n",
    "        info['rating'] = polarity - 1\n",
    "        dataset_test.append(info)\n",
    "\n",
    "    return dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b847378-d377-42b2-b213-80957826b954",
   "metadata": {},
   "source": [
    "- **Use function and save data as json file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c07c530-527a-445c-b80f-ea91f202d1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test dataset starts loading...\n",
      "The test dataset is now ready and saved as a json file!\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "print(\"The test dataset starts loading...\")\n",
    "\n",
    "# create json file\n",
    "test_set = womens_clothing_ecommerce_reviews()\n",
    "dataset_test_json = f'/workspace/data/dataset_test.json'\n",
    "with open(dataset_test_json, 'w') as json_file:\n",
    "    json.dump(test_set, json_file, indent=1)\n",
    "    \n",
    "print(\"The test dataset is now ready and saved as a json file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab16fa7-7a2d-457d-bfad-68bae9a2b3ef",
   "metadata": {},
   "source": [
    "## Step 3 - Use Lettria app for sentiment analysis\n",
    "\n",
    "- **Test Lettria model on data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9014a32-9f7c-451b-8e8c-a599f7d85ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis function for Lettria model on test dataset\n",
    "def lettria_sentiment(dataset_test):\n",
    "\n",
    "    # call partner model from the app deployed with OVHcloud AI Deploy - Lettria\n",
    "    url = \"https://73f75f90-73c3-4e08-8326-e3fef84e74e5.app.gra.ai.cloud.ovh.net/predict\"\n",
    "\n",
    "    # define headers and add token\n",
    "    headers = {'content-type': 'application/json',\n",
    "               'Accept-Charset': 'UTF-8'}\n",
    "\n",
    "    # analyse sentiment on texts from test set with Lettria\n",
    "    result_model_lettria = []\n",
    "    for i in range(len(dataset_test)):\n",
    "        result = {}\n",
    "        # add sentence (str)\n",
    "        result['review_text'] = dataset_test[i]['review_text']\n",
    "        # add sentiment (float [-1;1]) -> (int 0, 1, 2, 3, 4)\n",
    "        inp = json.dumps([dataset_test[i]['review_text']])\n",
    "        output = requests.post(url, data=inp, headers=headers).json()\n",
    "        score = output[0]['score']\n",
    "        result['rate_lettria'] = 0 if score < -0.6 \\\n",
    "                                    else 1 if -0.6<= score <-0.2 \\\n",
    "                                    else 2 if -0.2<= score <0.2  \\\n",
    "                                    else 3 if 0.2<= score <0.6 \\\n",
    "                                    else 4\n",
    "        result_model_lettria.append(result)\n",
    "\n",
    "    return result_model_lettria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3fcce6-2374-4ce7-a3fa-b292c0dfd466",
   "metadata": {},
   "source": [
    "- **Use function and time the process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552f5f2e-7543-4457-99e5-47e6f03defe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lettria model starts analysis...\n",
      "Lettria model process time: 65.11147165298462 seconds\n"
     ]
    }
   ],
   "source": [
    "# get sentiment analysis result\n",
    "print(\"The lettria model starts analysis...\")\n",
    "\n",
    "# time the inference\n",
    "start = time.time()\n",
    "\n",
    "# get sentiment analysis result\n",
    "lettria_output = lettria_sentiment(test_set)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Lettria model process time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ba257-9a8c-4a8e-acd5-0641c282e788",
   "metadata": {},
   "source": [
    "- **Save data as json file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83050ad-96db-4699-9c3e-f65234117508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json file\n",
    "result_lettria_json = '/workspace/results/result_model_lettria.json'\n",
    "with open(result_lettria_json, 'w') as json_file:\n",
    "    json.dump(lettria_output, json_file, indent=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
